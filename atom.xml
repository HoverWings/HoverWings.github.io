<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>HoverWings&#39; Site</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="hoverwings.site/"/>
  <updated>2019-06-19T17:38:55.060Z</updated>
  <id>hoverwings.site/</id>
  
  <author>
    <name>Xiang Pan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>RS_RL</title>
    <link href="hoverwings.site/2019/06/19/RS-RL/"/>
    <id>hoverwings.site/2019/06/19/RS-RL/</id>
    <published>2019-06-19T15:00:32.000Z</published>
    <updated>2019-06-19T17:38:55.060Z</updated>
    
    <content type="html"><![CDATA[<h2 id="参考资料">参考资料</h2><blockquote><ul><li><a href></a></li><li><a href></a></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;参考资料&quot;&gt;参考资料&lt;/h2&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

      
    
    </summary>
    
      <category term="Recommendation_System" scheme="hoverwings.site/categories/Recommendation-System/"/>
    
    
  </entry>
  
  <entry>
    <title>RS_GAN</title>
    <link href="hoverwings.site/2019/06/19/RS-GAN/"/>
    <id>hoverwings.site/2019/06/19/RS-GAN/</id>
    <published>2019-06-18T18:20:49.000Z</published>
    <updated>2019-06-19T17:34:29.940Z</updated>
    
    <content type="html"><![CDATA[<h1 id="seqgan">SeqGAN</h1><h1 id="infogan">InfoGAN</h1><h1 id="cfgan">CFGAN</h1><h1 id="thoughts">Thoughts</h1><p>利用G网络产生购物券种类 利用D网络判别购物券产生的有效性 利用conditional GAN产生特定的购物券</p><h2 id="参考资料">参考资料</h2><blockquote><ul><li><a href></a></li><li><a href></a></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;seqgan&quot;&gt;SeqGAN&lt;/h1&gt;
&lt;h1 id=&quot;infogan&quot;&gt;InfoGAN&lt;/h1&gt;
&lt;h1 id=&quot;cfgan&quot;&gt;CFGAN&lt;/h1&gt;
&lt;h1 id=&quot;thoughts&quot;&gt;Thoughts&lt;/h1&gt;
&lt;p&gt;利用G网络产生购物券种类 利用D网络判别购
      
    
    </summary>
    
      <category term="Recommendation_System" scheme="hoverwings.site/categories/Recommendation-System/"/>
    
    
  </entry>
  
  <entry>
    <title>RS_Explainability</title>
    <link href="hoverwings.site/2019/06/07/RS-Explainability/"/>
    <id>hoverwings.site/2019/06/07/RS-Explainability/</id>
    <published>2019-06-07T15:56:11.000Z</published>
    <updated>2019-06-19T17:34:29.940Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2019/06/07/RS-Explainability/ExplainableRS0.png" width="500px"></p><p><strong>PanXiang</strong> 2019.4.9</p><p><strong>Problem</strong></p><p>why such items are recommended</p><p>why they not only provideusers with the recommendations</p><p>effectiveness</p><p>efficiency</p><p>persuasiveness</p><p>user satisfaction</p><p>(how presented)display style:text/visual</p><p>(what information used)model:matrix factorization,topic modeling, graphbased models, deep learning, knowledge-graph embedding, association rule mining</p><p><strong>Time Line</strong></p><p><strong>CF(Memory-Based)</strong></p><p><strong>C</strong> <strong>ontent-</strong> <strong>B</strong> <strong>ased</strong> <strong>CF(feature based)</strong></p><p>(price, color, brand of the goods in e-commerce, or the genre, director, duration of the movies inreview systems)</p><p><strong>User-based CF</strong> <strong>(user embedding?)</strong></p><p><strong>Item-based CF(Item embedding?)</strong></p><p>MF(Model-Based)</p><p>生成式模型/判别式模型?</p><p><strong>MF</strong></p><p><strong>LFM(Latent Factor Model)</strong></p><p>m user</p><p>n item</p><p>A: user-(item favor value)</p><p>U: user-feature</p><p>V: feature-(itemfavor value)</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS1.png" width="277px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS2.png" width="500px"></p><p><strong>MF</strong></p><p><strong>LFM(Latent Factor Model)</strong> <strong>/Singular Value Decomposition(SVD)?</strong></p><p>m user</p><p>n item</p><p>A: user-(item favor value)</p><p>U: user-feature</p><p>V: feature-(itemfavor value)</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS3.png" width="277px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS4.png" width="451px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS5.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS6.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS7.png" width="227px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS8.png" width="500px"></p><p>yi反应喜好偏置</p><p>I(u)所有交互</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS9.png" width="500px"></p><p>behaviour can reflect favor</p><p>2008 KDD Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model</p><p><strong>E</strong> <strong>FM(Explicit Factor Model)</strong></p><p>+explicit user opinions</p><p>explicit product features</p><p>user opinions by phrase-level sentiment analysis on user reviews</p><p>generate according to specific product features to the user’s interests and the hidden features learned</p><p>SIGIR 2014Explicit Factor Models for Explainable Recommendation based on Phrase-level Sentiment Analysis</p><p><strong>EFM(Explicit Factor Model)</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS10.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS11.png" width="500px"></p><p>SIGIR 2014Explicit Factor Models for Explainable Recommendation based on Phrase-level Sentiment Analysis</p><p><strong>EFM(Explicit Factor Model)</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS12.png" width="500px"></p><p>N=5 for five stars</p><p>feature Fj is mentioned by user ui for tij times</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS13.png" width="500px"></p><p>Fj is mentioned for k times on item pi</p><p>SIGIR 2014Explicit Factor Models for Explainable Recommendation based on Phrase-level Sentiment Analysis</p><p><strong>EFM(Explicit Factor Model)</strong></p><p><strong>Explicit</strong> <strong>features</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS14.png" width="500px"></p><p>feature: screen/earphone</p><p>factor: ???</p><p>X:user-feature attention matrix</p><p>Y:item-feature quality matrix</p><p>U1 user- factor</p><p>V feature-factor</p><p>U2 item- factor</p><p>r factor nums</p><p>m user</p><p>p feature</p><p>n item</p><p>SIGIR 2014Explicit Factor Models for Explainable Recommendation based on Phrase-level Sentiment Analysis</p><p><strong>EFM(Explicit Factor Model)</strong></p><p><strong>Latent</strong> <strong>f</strong> <strong>actors</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS15.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS16.png" width="500px"></p><p>When r = 0, this model reduces to a traditional latent factorization model on user-item rating matrix A</p><p>which means that the explicit features are not used for recommendations</p><p><strong>EFM(Explicit Factor Model)</strong> <strong>+SVD++?</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS17.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS18.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS19.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS20.png" width="410px"></p><p>SIGIR’18 Explainable Recommendation via Multi-Task Learning in Opinionated Text Data</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS21.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS22.png" width="500px"></p><p><strong>ConvMF=CNN+PMF</strong></p><p><strong>PMF</strong></p><p>R: score Mat</p><p>posterior probability</p><p>M item</p><p>N doc</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS23.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS24.png" width="481px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS25.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS26.png" width="156px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS27.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS28.png" width="128px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS29.png" width="129px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS30.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS31.png" width="381px"></p><p>2016Convolutional matrix factorization for document context-aware recommendation</p><p><strong>CNN:</strong></p><p><strong>(Music:Fourier-&gt;image-&gt;CNN predict</strong></p><p><strong>Genetrate Feature)</strong></p><p>Conv -Classification-&gt;feature extraction</p><p>MF -Regression</p><p>2016Convolutional matrix factorization for document context-aware recommendation</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS32.png" width="500px"></p><p>Z[t]:update gate vector</p><p>R[t]:reset gate vector</p><p>RecSys17 Sequential User-based Recurrent Neural Network Recommendations</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS33.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS34.png" width="491px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS35.png" width="500px"></p><p>RecSys17 Sequential User-based Recurrent Neural Network Recommendations</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS36.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS37.png" width="500px"></p><p><strong>Text</strong></p><p><strong>Sentence:</strong></p><p><strong>Topic words:(features)</strong></p><p><strong>Visual</strong></p><p><strong>Friends</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS38.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS39.png" width="473px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS40.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS41.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS42.png" width="500px"></p><p>generated character by</p><p>character</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS43.png" width="500px"></p><p>concatenated word</p><p>embeddings of user, item, and rating</p><p>2018Automatic Generation of Natural Language Explanations</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS44.png" width="500px"></p><p><strong>Text-based(NLP)</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS45.png" width="500px"></p><p>2018Automatic Generation of Natural Language Explanations</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS46.png" width="500px"></p><p><strong>Text-based(NLP)</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS47.png" width="500px"></p><p>2018Automatic Generation of Natural Language Explanations</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS48.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS49.png" width="500px"></p><p><strong>Knowledge-base</strong> <strong>=path comlpetion</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS50.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS51.png" width="500px"></p><p>2019Unifying Knowledge Graph Learning and Recommendation: Towards a Better Understanding of User Preferences</p><p><strong>Knowledge-base</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS52.png" width="500px"></p><p>AAAI2019Unifying Knowledge Graph Learning and Recommendation: Towards a Better Understanding of User Preferences</p><p><strong>Knowledge-base</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS53.png" width="500px"></p><p>AAAI2019Unifying Knowledge Graph Learning and Recommendation: Towards a Better Understanding of User Preferences</p><p><strong>Knowledge-base</strong></p><p>TransE</p><p>TransH</p><p>It assumes that each relation</p><p>owns a hyperplane, and the translation between head entity and</p><p>tail entity is valid only if they are projected to the same hyperplane</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS54.png" width="139px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS55.png" width="176px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS56.png" width="500px"></p><p>WWW2019Unifying Knowledge Graph Learning and Recommendation:Towards a Better Understanding of User Preferences</p><p><strong>Knowledge-base</strong></p><p>TransH</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS57.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS58.png" width="242px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS59.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS60.png" width="500px"></p><p>WWW2019Unifying Knowledge Graph Learning and Recommendation:Towards a Better Understanding of User Preferences</p><p><strong>Evaluation-RS</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS61.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS62.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS63.png" width="500px"></p><p>reli = 1 if the i-th element is a positive item</p><p><strong>Evaluation</strong> <strong>-Explainable</strong></p><p>explainability</p><p>EP:explainability precision</p><p>ER:explainabilityrecall</p><p>Text:</p><p>BLUE: 不同长度的统计值差异计算</p><p>Rough(Recall-Oriented Understudy for Gisting Evaluation)</p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS64.png" width="500px"></p><p>LCSLongest Child String</p><p>Open Question</p><p>DL explainability</p><p>Heterogenous Information Modeling</p><p>Text/Image/Audio Search</p><p>Natural Language Generation for Explanation</p><p>QA System</p><p>Explanation beyond Persuasiveness</p><p>letting the user know why not to buy a certain product</p><p>the system can help to save time for the users and to win user’s trustin the system</p><p>Open Question</p><p>Aggregation of Different Explanations</p><p><strong>Explainable ML</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS65.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS66.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS67.png" width="500px"></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS68.png" width="500px"></p><p><strong>Explainable</strong> <strong>D</strong> <strong>L</strong></p><p><img src="/2019/06/07/RS-Explainability/ExplainableRS69.png" width="500px"></p><p>Understanding Black-box Predictions via Influence Functions</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/2019/06/07/RS-Explainability/ExplainableRS0.png&quot; width=&quot;500px&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PanXiang&lt;/strong&gt; 2019.4.9&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Probl
      
    
    </summary>
    
      <category term="Recommendation_System" scheme="hoverwings.site/categories/Recommendation-System/"/>
    
    
  </entry>
  
  <entry>
    <title>ML in Complex Netetwork</title>
    <link href="hoverwings.site/2019/06/04/ML-in-Complex-Netetwork/"/>
    <id>hoverwings.site/2019/06/04/ML-in-Complex-Netetwork/</id>
    <published>2019-06-04T06:34:18.000Z</published>
    <updated>2019-06-18T17:14:07.799Z</updated>
    
    <content type="html"><![CDATA[<!-- $size: 4:3 --><!-- page_number: true --><center><font size="11">Machine Learning in <br> Complex Network </font></center><p>Xiang Pan<br>Supervised By: Hong Huang<br>6/2/2019 ---</p><h1 id="complex-network">Complex Network</h1><p>A <strong>Complex Network</strong> is a graph (network) with non-trivial topological features—features that do not occur in simple networks such as lattices or random graphs but often occur in graphs modelling of real systems.</p><p><strong>Node and Link</strong>:The general model for the world <strong>CS</strong>?:Compute and Storage</p><hr><h2 id="traditional-method">Traditional Method</h2><ul><li>Dynamics<ul><li>Deep Walk<ul><li>Population Predication</li></ul></li><li>Propagation Theory<ul><li>Infectious Diseases Propagation</li></ul></li></ul></li><li>Cluster Theory<ul><li>Aggregation<ul><li>Community Dection</li></ul></li></ul></li></ul><h2 id="mlcomplex-network">ML+Complex Network</h2><ul><li>More information than Vector<ul><li>Build and represent do not loss critical information<ul><li>porpertity</li><li>structure</li></ul></li><li>Adapt to more general dataset type</li></ul></li><li>More Method<ul><li><strong>Graph CNN/DNN/VAE/GAN</strong></li></ul></li></ul><hr><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-16-38-16.png"></p><!-- <img src="./ML-in-Complex-Netetwork/2019-06-03-16-38-16.png" width = "400" height = "400" div align= center /> --><hr><h1 id="pipeline">Pipeline</h1><h2 id="ml-pipeline">ML PipeLine</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">digraph G</span><br><span class="line">&#123;</span><br><span class="line">    &quot;Select Topic&quot;-&gt;&quot;Preparing Data Set(Data Clean)&quot;-&gt;&quot;Feature Engineering&quot;-&gt;&quot;Bilud Model&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="build-network">Build Network</h1><h2 id="defination">Defination</h2><h3 id="node">Node</h3><p><span class="math display">\[N=O(Node)\]</span> can be the anything of the world The understanding</p><hr><h3 id="link">Link</h3><h4 id="similarity-and-diffidence">Similarity And Diffidence</h4><p><span class="math display">\[{ V*V \in R  }\]</span></p><p><span class="math display">\[{ S_{ij}=s(v_i,v_j)  }\]</span></p><p>The <strong>Similarity Function</strong> can be the diastance of vector representation <span class="math display">\[{ D_{ij}=d(v_i,v_j)  }\]</span></p><hr><p>The <strong>Diffidence Function</strong> can be calculated by the Similarity Function <span class="math display">\[{    d(v_i,v_j)=\sqrt {s(v_i,v_i)+s(v_j,v_j)-2s(v_i,v_j)}}\]</span></p><p><span class="math display">\[{ P_{ij}=\alpha * S_{ij} + \beta *1/D_{ij}       }\]</span></p><p>Then set a <strong>threshhold</strong> to build the link</p><hr><h4 id="how-to-determine-the-threshholdhyperparameter">How to determine the threshhold(hyperparameter)?</h4><ul><li>Network sparsity(Experience) &gt;After obtaining the base image matrix and coefficient matrix of non-negative matrix factorization (NMF), Hoyer [1] proposed that the degree of difference between the L1 norm and the L2 norm can be used to measure the sparsity of the matrix after decomposition.</li><li>Training result<ul><li>Auto ML</li></ul></li></ul><h1 id="representataion">Representataion</h1><p><strong>Network Representation</strong>:Using some method to reduce the dimension of the data, then the network can be represent as a <strong>Vector</strong> - <strong>Graph Embedding</strong></p><hr><h2 id="mf">MF</h2><p>M is an <strong>Orthogonal matrix</strong> ### SVD <img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-47-20.png"></p><hr><p><span class="math display">\[M \in Space_{node * node}\]</span></p><p><span class="math inline">\(U\)</span> is the main Vector representation <span class="math inline">\(V= \Sigma * V^*\)</span> is the Background Vector Repersentation</p><hr><h2 id="deep-walk">Deep Walk</h2><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-02-28.png"></p><h4 id="hierarchical-huffman-tree">Hierarchical Huffman Tree</h4><hr><h3 id="can-be-understood-by-mf">Can be understood by MF?</h3><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-11-02.png"></p><hr><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-11-38.png"></p><hr><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-24-32.png"></p><hr><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-10-07.png"></p><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-25-36.png"></p><h2 id="pte">PTE</h2><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-27-13.png"></p><h2 id="node2vec-2nd-order-random-walk">node2vec — 2nd Order Random Walk</h2><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-28-42.png"></p><hr><h3 id="node2vec-as-implicit-matrix-factorization">node2vec as Implicit Matrix Factorization</h3><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-29-10.png"></p><hr><h2 id="everything-is-mf">Everything is MF</h2><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-16-54-40.png"></p><hr><h1 id="netmf">NetMF</h1><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-30-24.png"></p><hr><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-30-45.png"></p><hr><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-31-06.png"></p><h1 id="application">Application</h1><h2 id="abstract">Abstract</h2><ul><li>Link Prediction</li><li>Clustering</li><li>Dynamic Network Analysis</li></ul><h2 id="real-world">Real World</h2><ul><li>Infectious Diseases</li><li>Academic Network</li><li>Media Web<ul><li><strong>Recommendation System(RS)</strong></li><li>Terrorist Dection</li></ul></li></ul><hr><h1 id="recommendation-system">Recommendation System</h1><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-33-45.png"></p><hr><p><img src="/2019/06/04/ML-in-Complex-Netetwork/2019-06-03-17-34-02.png"></p><hr><h1 id="reference">Reference</h1><ul><li><a href="https://www.aminer.cn/nrl_www2019" target="_blank" rel="noopener">Jie Tang's Tutorial in WWW 2019</a></li><li><a href>Machine Leaning in Complex Network</a></li></ul><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- $size: 4:3 --&gt;
&lt;!-- page_number: true --&gt;
&lt;center&gt;
&lt;font size=&quot;11&quot;&gt;Machine Learning in &lt;br&gt; Complex Network &lt;/font&gt;
&lt;/center&gt;
&lt;p&gt;Xiang 
      
    
    </summary>
    
      <category term="Complex_Network" scheme="hoverwings.site/categories/Complex-Network/"/>
    
    
  </entry>
  
  <entry>
    <title>RS_Transformer</title>
    <link href="hoverwings.site/2019/06/04/RS-Transformer/"/>
    <id>hoverwings.site/2019/06/04/RS-Transformer/</id>
    <published>2019-06-03T18:25:12.000Z</published>
    <updated>2019-06-19T17:34:29.940Z</updated>
    
    <content type="html"><![CDATA[<h1 id="behavior-sequence-transformer-for-e-commerce-recommendation-in-alibaba">Behavior Sequence Transformer for E-commerce Recommendation in Alibaba</h1><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-10-36.png"></p><hr><h1 id="abstract">Abstract</h1><ul><li><strong>Embedding&amp;MLP paradigm</strong>: raw features are embedded into lowdimensional vectors<ul><li>ignoring the sequential nature of users’ behaviors</li></ul></li><li><strong>Transformer model</strong> to capture the sequential signals underlying users’ behavior sequences for recommendation</li></ul><hr><h1 id="transforemerattention-is-all-you-need">Transforemer(Attention is all you need)</h1><h2 id="architecture">Architecture</h2><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-16-51.png"></p><hr><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-17-12.png"></p><hr><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-18-04.png"></p><p>Every encoder do not share their weights</p><hr><h2 id="self-attention-encoder">Self-Attention Encoder</h2><p>Input Word-&gt;Embededing <span class="math display">\[ q_1=V*W_q \]</span> <span class="math display">\[ k_1=V*W_k \]</span> <span class="math display">\[ v_1=V*W_v \]</span></p><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-30-16.png"></p><hr><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-31-21.png"></p><hr><p><strong>Position</strong>: diffierent distance to different pos</p><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-34-53.png"></p><hr><h2 id="decoder">Decoder</h2><p>The Unis number is O(Word)<br><img src="/2019/06/04/RS-Transformer/2019-06-04-01-39-58.png"></p><hr><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-36-45.png"></p><hr><h2 id="loss">loss</h2><p>The differience of 2 distribution - Cross Entropy - KL Distance</p><hr><h1 id="bst">BST</h1><h2 id="architecture-1">Architecture</h2><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-45-45.png"></p><hr><h2 id="feature">Feature</h2><h3 id="general-embedding">General Embedding</h3><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-46-58.png"></p><hr><h3 id="positional-embedding">Positional embedding</h3><p><span class="math display">\[pos(v_i) = t(v_t) − t(v_i)\]</span></p><p>where <span class="math inline">\(t(v_t)\)</span> represents the recommending time and <span class="math inline">\(t(v_i)\)</span> the timestamp when user click item <span class="math inline">\(v_i\)</span>.</p><hr><h2 id="transformer">Transformer</h2><h3 id="self-attention-layer">Self-attention layer</h3><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-49-56.png"></p><hr><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-50-42.png"></p><hr><h3 id="point-wise-feed-forward-networks">Point-wise Feed-Forward Networks</h3><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-51-23.png"></p><hr><h2 id="mlp-layers-and-loss-function">MLP layers and Loss function</h2><p><strong>binary classification problem</strong><br><img src="/2019/06/04/RS-Transformer/2019-06-04-01-52-08.png"></p><hr><h1 id="result">Result</h1><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-53-02.png"> <img src="/2019/06/04/RS-Transformer/2019-06-04-01-53-15.png"></p><hr><p><img src="/2019/06/04/RS-Transformer/2019-06-04-01-53-32.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;behavior-sequence-transformer-for-e-commerce-recommendation-in-alibaba&quot;&gt;Behavior Sequence Transformer for E-commerce Recommendation 
      
    
    </summary>
    
      <category term="Recommendation_System" scheme="hoverwings.site/categories/Recommendation-System/"/>
    
    
  </entry>
  
</feed>
